{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Conv autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "14bvPLjn7KkAMdtJ58pq9rmJJl_IfV8i8",
      "authorship_tag": "ABX9TyPdNJbuV5i/jwDNjYYDXpvF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhuchangyan/Multimode-fiber-Image-reconstruction/blob/master/Conv_autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LHQx3j-5lMP",
        "colab_type": "text"
      },
      "source": [
        "2020/3/13 尝试了Dense autoencoder之后，效果一般，勉强能出数字1和9.因此决定尝试convolutional autoencoer\n",
        "\n",
        "2020/3/14 成功将ssim作为loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvKEI1QRZJTy",
        "colab_type": "code",
        "outputId": "f9b7ad90-1f8c-4885-ec7f-b44f83cae9aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "from keras.layers import Input, Dense , Dropout\n",
        "from keras.models import Model\n",
        "import pickle\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1DkPMCkhH28",
        "colab_type": "code",
        "outputId": "f52e1ed7-e948-414b-98d2-3a618fe8ce6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My Drive/Colab Notebooks/MMF data/\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/MMF data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oV6_TG2vhXDC",
        "colab_type": "code",
        "outputId": "bb2ae8b2-fabe-4e81-c508-7876a229aa21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd Mnist\\ image\\ data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/MMF data/Mnist image data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMRVN2jXhVLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('resize_10000.dat','rb') as f:\n",
        "  imgs = pickle.load(f)\n",
        "\n",
        "with open('resize_10000_SLM.dat','rb') as f:\n",
        "  origins = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niCSquPviYeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in range(10000):\n",
        "#   imgs[i] = imgs[i].flatten()\n",
        "#   origins[i] = origins[i].flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYWv79mykTK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_imgs = []\n",
        "train_origins = []\n",
        "\n",
        "test_imgs = []\n",
        "test_origins =[]\n",
        "\n",
        "for i in range(8000):\n",
        "  train_imgs.append(imgs[i].reshape(28,28,1))\n",
        "  train_origins.append(origins[i].reshape(28,28,1))\n",
        "\n",
        "for i in range(8000,10000):\n",
        "  test_imgs.append(imgs[i].reshape(28,28,1))\n",
        "  test_origins.append(origins[i].reshape(28,28,1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRpdC8JYsFxr",
        "colab_type": "text"
      },
      "source": [
        "Set up neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUXk9KL678NU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVl35Hd1ZX0k",
        "colab_type": "code",
        "outputId": "aeb3d02c-1e42-45e8-98a4-41a23a836a02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "source": [
        "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
        "\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
        "\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "\n",
        "autoencoder = Model(input_img, decoded)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kU4xTS7Z6i9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder = Model(input_img, encoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roEie-vE16oA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def ssim_loss(y_true, y_pred):\n",
        "  return 1.0-tf.reduce_mean(tf.image.ssim(y_true, y_pred, 2.0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8YKxSPgaii8",
        "colab_type": "code",
        "outputId": "5350943d-88de-431a-c1b4-e064f1d8f876",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "autoencoder.compile(optimizer = 'adam', loss = ssim_loss , metrics = [ssim_loss, 'accuracy'])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "821aN5nyavaL",
        "colab_type": "code",
        "outputId": "13aa8f8d-43ae-476a-fd02-2151549aee34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "train_imgs = np.array(train_imgs).astype('float32') / 255.\n",
        "train_origins = np.array(train_origins).astype('float32') / 255.\n",
        "\n",
        "test_imgs = np.array(test_imgs).astype('float32') / 255.\n",
        "test_origins = np.array(test_origins).astype('float32') / 255.\n",
        "\n",
        "\n",
        "print (train_imgs.shape)\n",
        "print (test_imgs.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8000, 28, 28, 1)\n",
            "(2000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEOYKfzvqrWG",
        "colab_type": "code",
        "outputId": "627abdad-49c5-4466-bd5e-70ebfb67667d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        }
      },
      "source": [
        "autoencoder.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 128)       1280      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 14, 14, 64)        73792     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 7, 7, 32)          18464     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 4, 4, 32)          9248      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 8, 8, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 64)          18496     \n",
            "_________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 14, 14, 128)       73856     \n",
            "_________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2 (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 28, 28, 1)         1153      \n",
            "=================================================================\n",
            "Total params: 196,289\n",
            "Trainable params: 196,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rB-AfZbCbAY7",
        "colab_type": "code",
        "outputId": "2a3da811-8e7f-4612-a7f9-804b656e36e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = autoencoder.fit(train_imgs, train_origins,\n",
        "                epochs=50,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(test_imgs, test_origins))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/150\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "8000/8000 [==============================] - 5s 628us/step - loss: 0.8449 - ssim_loss: 0.8449 - acc: 0.6601 - val_loss: 0.8067 - val_ssim_loss: 0.8067 - val_acc: 0.7378\n",
            "Epoch 2/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.7797 - ssim_loss: 0.7797 - acc: 0.7657 - val_loss: 0.7859 - val_ssim_loss: 0.7859 - val_acc: 0.7507\n",
            "Epoch 3/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.7568 - ssim_loss: 0.7568 - acc: 0.7710 - val_loss: 0.7490 - val_ssim_loss: 0.7490 - val_acc: 0.7675\n",
            "Epoch 4/150\n",
            "8000/8000 [==============================] - 2s 217us/step - loss: 0.7318 - ssim_loss: 0.7318 - acc: 0.7677 - val_loss: 0.7266 - val_ssim_loss: 0.7266 - val_acc: 0.7448\n",
            "Epoch 5/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.6923 - ssim_loss: 0.6923 - acc: 0.7659 - val_loss: 0.7120 - val_ssim_loss: 0.7120 - val_acc: 0.7550\n",
            "Epoch 6/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.6754 - ssim_loss: 0.6754 - acc: 0.7678 - val_loss: 0.6963 - val_ssim_loss: 0.6963 - val_acc: 0.7575\n",
            "Epoch 7/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.6596 - ssim_loss: 0.6596 - acc: 0.7687 - val_loss: 0.6782 - val_ssim_loss: 0.6782 - val_acc: 0.7726\n",
            "Epoch 8/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.6420 - ssim_loss: 0.6420 - acc: 0.7709 - val_loss: 0.6579 - val_ssim_loss: 0.6579 - val_acc: 0.7606\n",
            "Epoch 9/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.6255 - ssim_loss: 0.6255 - acc: 0.7729 - val_loss: 0.6501 - val_ssim_loss: 0.6501 - val_acc: 0.7596\n",
            "Epoch 10/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.6062 - ssim_loss: 0.6062 - acc: 0.7758 - val_loss: 0.6097 - val_ssim_loss: 0.6097 - val_acc: 0.7722\n",
            "Epoch 11/150\n",
            "8000/8000 [==============================] - 2s 217us/step - loss: 0.5789 - ssim_loss: 0.5789 - acc: 0.7790 - val_loss: 0.5919 - val_ssim_loss: 0.5919 - val_acc: 0.7753\n",
            "Epoch 12/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.5585 - ssim_loss: 0.5585 - acc: 0.7815 - val_loss: 0.5742 - val_ssim_loss: 0.5742 - val_acc: 0.7796\n",
            "Epoch 13/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.5433 - ssim_loss: 0.5433 - acc: 0.7831 - val_loss: 0.5667 - val_ssim_loss: 0.5667 - val_acc: 0.7730\n",
            "Epoch 14/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.5302 - ssim_loss: 0.5302 - acc: 0.7845 - val_loss: 0.5491 - val_ssim_loss: 0.5491 - val_acc: 0.7876\n",
            "Epoch 15/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.5185 - ssim_loss: 0.5185 - acc: 0.7862 - val_loss: 0.5318 - val_ssim_loss: 0.5318 - val_acc: 0.7810\n",
            "Epoch 16/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.5011 - ssim_loss: 0.5011 - acc: 0.7876 - val_loss: 0.5369 - val_ssim_loss: 0.5369 - val_acc: 0.7796\n",
            "Epoch 17/150\n",
            "8000/8000 [==============================] - 2s 217us/step - loss: 0.4943 - ssim_loss: 0.4943 - acc: 0.7883 - val_loss: 0.5126 - val_ssim_loss: 0.5126 - val_acc: 0.7863\n",
            "Epoch 18/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.4827 - ssim_loss: 0.4827 - acc: 0.7894 - val_loss: 0.5242 - val_ssim_loss: 0.5242 - val_acc: 0.7882\n",
            "Epoch 19/150\n",
            "8000/8000 [==============================] - 2s 217us/step - loss: 0.4768 - ssim_loss: 0.4768 - acc: 0.7898 - val_loss: 0.4995 - val_ssim_loss: 0.4995 - val_acc: 0.7895\n",
            "Epoch 20/150\n",
            "8000/8000 [==============================] - 2s 218us/step - loss: 0.4659 - ssim_loss: 0.4659 - acc: 0.7910 - val_loss: 0.5016 - val_ssim_loss: 0.5016 - val_acc: 0.7922\n",
            "Epoch 21/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.4602 - ssim_loss: 0.4602 - acc: 0.7914 - val_loss: 0.4856 - val_ssim_loss: 0.4856 - val_acc: 0.7870\n",
            "Epoch 22/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.4512 - ssim_loss: 0.4512 - acc: 0.7920 - val_loss: 0.4822 - val_ssim_loss: 0.4822 - val_acc: 0.7859\n",
            "Epoch 23/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.4453 - ssim_loss: 0.4453 - acc: 0.7926 - val_loss: 0.4854 - val_ssim_loss: 0.4854 - val_acc: 0.7883\n",
            "Epoch 24/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.4432 - ssim_loss: 0.4432 - acc: 0.7924 - val_loss: 0.4727 - val_ssim_loss: 0.4727 - val_acc: 0.7905\n",
            "Epoch 25/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.4337 - ssim_loss: 0.4337 - acc: 0.7932 - val_loss: 0.4671 - val_ssim_loss: 0.4671 - val_acc: 0.7910\n",
            "Epoch 26/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.4286 - ssim_loss: 0.4286 - acc: 0.7934 - val_loss: 0.4614 - val_ssim_loss: 0.4614 - val_acc: 0.7870\n",
            "Epoch 27/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.4242 - ssim_loss: 0.4242 - acc: 0.7939 - val_loss: 0.4672 - val_ssim_loss: 0.4672 - val_acc: 0.7860\n",
            "Epoch 28/150\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.4207 - ssim_loss: 0.4207 - acc: 0.7941 - val_loss: 0.4586 - val_ssim_loss: 0.4586 - val_acc: 0.7908\n",
            "Epoch 29/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.4154 - ssim_loss: 0.4154 - acc: 0.7946 - val_loss: 0.4550 - val_ssim_loss: 0.4550 - val_acc: 0.7905\n",
            "Epoch 30/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.4121 - ssim_loss: 0.4121 - acc: 0.7947 - val_loss: 0.4751 - val_ssim_loss: 0.4751 - val_acc: 0.7952\n",
            "Epoch 31/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.4074 - ssim_loss: 0.4074 - acc: 0.7951 - val_loss: 0.4457 - val_ssim_loss: 0.4457 - val_acc: 0.7908\n",
            "Epoch 32/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.3998 - ssim_loss: 0.3998 - acc: 0.7956 - val_loss: 0.4433 - val_ssim_loss: 0.4433 - val_acc: 0.7943\n",
            "Epoch 33/150\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.3979 - ssim_loss: 0.3979 - acc: 0.7958 - val_loss: 0.4418 - val_ssim_loss: 0.4418 - val_acc: 0.7931\n",
            "Epoch 34/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.3951 - ssim_loss: 0.3951 - acc: 0.7960 - val_loss: 0.4386 - val_ssim_loss: 0.4386 - val_acc: 0.7927\n",
            "Epoch 35/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.3912 - ssim_loss: 0.3912 - acc: 0.7962 - val_loss: 0.4330 - val_ssim_loss: 0.4330 - val_acc: 0.7915\n",
            "Epoch 36/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.3855 - ssim_loss: 0.3855 - acc: 0.7967 - val_loss: 0.4427 - val_ssim_loss: 0.4427 - val_acc: 0.7900\n",
            "Epoch 37/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.3898 - ssim_loss: 0.3898 - acc: 0.7963 - val_loss: 0.4323 - val_ssim_loss: 0.4323 - val_acc: 0.7891\n",
            "Epoch 38/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.3811 - ssim_loss: 0.3811 - acc: 0.7971 - val_loss: 0.4275 - val_ssim_loss: 0.4275 - val_acc: 0.7911\n",
            "Epoch 39/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.3798 - ssim_loss: 0.3798 - acc: 0.7972 - val_loss: 0.4239 - val_ssim_loss: 0.4239 - val_acc: 0.7903\n",
            "Epoch 40/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.3728 - ssim_loss: 0.3728 - acc: 0.7975 - val_loss: 0.4241 - val_ssim_loss: 0.4241 - val_acc: 0.7895\n",
            "Epoch 41/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.3691 - ssim_loss: 0.3691 - acc: 0.7977 - val_loss: 0.4322 - val_ssim_loss: 0.4322 - val_acc: 0.7925\n",
            "Epoch 42/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.3681 - ssim_loss: 0.3681 - acc: 0.7978 - val_loss: 0.4288 - val_ssim_loss: 0.4288 - val_acc: 0.7901\n",
            "Epoch 43/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.3649 - ssim_loss: 0.3649 - acc: 0.7980 - val_loss: 0.4212 - val_ssim_loss: 0.4212 - val_acc: 0.7915\n",
            "Epoch 44/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.3623 - ssim_loss: 0.3623 - acc: 0.7981 - val_loss: 0.4201 - val_ssim_loss: 0.4201 - val_acc: 0.7965\n",
            "Epoch 45/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.3578 - ssim_loss: 0.3578 - acc: 0.7986 - val_loss: 0.4192 - val_ssim_loss: 0.4192 - val_acc: 0.7915\n",
            "Epoch 46/150\n",
            "8000/8000 [==============================] - 2s 221us/step - loss: 0.3587 - ssim_loss: 0.3587 - acc: 0.7984 - val_loss: 0.4125 - val_ssim_loss: 0.4125 - val_acc: 0.7960\n",
            "Epoch 47/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.3530 - ssim_loss: 0.3530 - acc: 0.7988 - val_loss: 0.4201 - val_ssim_loss: 0.4201 - val_acc: 0.7961\n",
            "Epoch 48/150\n",
            "8000/8000 [==============================] - 2s 218us/step - loss: 0.3526 - ssim_loss: 0.3526 - acc: 0.7989 - val_loss: 0.4144 - val_ssim_loss: 0.4144 - val_acc: 0.7898\n",
            "Epoch 49/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.3507 - ssim_loss: 0.3507 - acc: 0.7989 - val_loss: 0.4075 - val_ssim_loss: 0.4075 - val_acc: 0.7940\n",
            "Epoch 50/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.3444 - ssim_loss: 0.3444 - acc: 0.7994 - val_loss: 0.4088 - val_ssim_loss: 0.4088 - val_acc: 0.7950\n",
            "Epoch 51/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.3430 - ssim_loss: 0.3430 - acc: 0.7993 - val_loss: 0.4116 - val_ssim_loss: 0.4116 - val_acc: 0.7923\n",
            "Epoch 52/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.3400 - ssim_loss: 0.3400 - acc: 0.7996 - val_loss: 0.4052 - val_ssim_loss: 0.4052 - val_acc: 0.7923\n",
            "Epoch 53/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.3399 - ssim_loss: 0.3399 - acc: 0.7997 - val_loss: 0.4073 - val_ssim_loss: 0.4073 - val_acc: 0.7954\n",
            "Epoch 54/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.3396 - ssim_loss: 0.3396 - acc: 0.7997 - val_loss: 0.4025 - val_ssim_loss: 0.4025 - val_acc: 0.7952\n",
            "Epoch 55/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.3345 - ssim_loss: 0.3345 - acc: 0.8000 - val_loss: 0.4049 - val_ssim_loss: 0.4049 - val_acc: 0.7918\n",
            "Epoch 56/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.3344 - ssim_loss: 0.3344 - acc: 0.7999 - val_loss: 0.4234 - val_ssim_loss: 0.4234 - val_acc: 0.7886\n",
            "Epoch 57/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.3387 - ssim_loss: 0.3387 - acc: 0.7996 - val_loss: 0.4027 - val_ssim_loss: 0.4027 - val_acc: 0.7946\n",
            "Epoch 58/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.3291 - ssim_loss: 0.3291 - acc: 0.8004 - val_loss: 0.4151 - val_ssim_loss: 0.4151 - val_acc: 0.7980\n",
            "Epoch 59/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.3288 - ssim_loss: 0.3288 - acc: 0.8004 - val_loss: 0.4007 - val_ssim_loss: 0.4007 - val_acc: 0.7919\n",
            "Epoch 60/150\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.3239 - ssim_loss: 0.3239 - acc: 0.8004 - val_loss: 0.4015 - val_ssim_loss: 0.4015 - val_acc: 0.7964\n",
            "Epoch 61/150\n",
            "8000/8000 [==============================] - 2s 212us/step - loss: 0.3235 - ssim_loss: 0.3235 - acc: 0.8006 - val_loss: 0.4068 - val_ssim_loss: 0.4068 - val_acc: 0.7956\n",
            "Epoch 62/150\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.3258 - ssim_loss: 0.3258 - acc: 0.8006 - val_loss: 0.4026 - val_ssim_loss: 0.4026 - val_acc: 0.7911\n",
            "Epoch 63/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.3232 - ssim_loss: 0.3232 - acc: 0.8005 - val_loss: 0.3960 - val_ssim_loss: 0.3960 - val_acc: 0.7927\n",
            "Epoch 64/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.3152 - ssim_loss: 0.3152 - acc: 0.8010 - val_loss: 0.3951 - val_ssim_loss: 0.3951 - val_acc: 0.7966\n",
            "Epoch 65/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.3171 - ssim_loss: 0.3171 - acc: 0.8009 - val_loss: 0.3980 - val_ssim_loss: 0.3980 - val_acc: 0.7942\n",
            "Epoch 66/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.3177 - ssim_loss: 0.3177 - acc: 0.8009 - val_loss: 0.3951 - val_ssim_loss: 0.3951 - val_acc: 0.7961\n",
            "Epoch 67/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.3152 - ssim_loss: 0.3152 - acc: 0.8011 - val_loss: 0.4178 - val_ssim_loss: 0.4178 - val_acc: 0.7979\n",
            "Epoch 68/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.3238 - ssim_loss: 0.3238 - acc: 0.8007 - val_loss: 0.3932 - val_ssim_loss: 0.3932 - val_acc: 0.7954\n",
            "Epoch 69/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.3098 - ssim_loss: 0.3098 - acc: 0.8015 - val_loss: 0.3932 - val_ssim_loss: 0.3932 - val_acc: 0.7931\n",
            "Epoch 70/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.3082 - ssim_loss: 0.3082 - acc: 0.8014 - val_loss: 0.3928 - val_ssim_loss: 0.3928 - val_acc: 0.7955\n",
            "Epoch 71/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.3088 - ssim_loss: 0.3088 - acc: 0.8015 - val_loss: 0.3921 - val_ssim_loss: 0.3921 - val_acc: 0.7924\n",
            "Epoch 72/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.3039 - ssim_loss: 0.3039 - acc: 0.8016 - val_loss: 0.3882 - val_ssim_loss: 0.3882 - val_acc: 0.7953\n",
            "Epoch 73/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.3015 - ssim_loss: 0.3015 - acc: 0.8019 - val_loss: 0.3901 - val_ssim_loss: 0.3901 - val_acc: 0.7948\n",
            "Epoch 74/150\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.3002 - ssim_loss: 0.3002 - acc: 0.8020 - val_loss: 0.3889 - val_ssim_loss: 0.3889 - val_acc: 0.7941\n",
            "Epoch 75/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.3005 - ssim_loss: 0.3005 - acc: 0.8020 - val_loss: 0.3912 - val_ssim_loss: 0.3912 - val_acc: 0.7960\n",
            "Epoch 76/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.2982 - ssim_loss: 0.2982 - acc: 0.8022 - val_loss: 0.3885 - val_ssim_loss: 0.3885 - val_acc: 0.7955\n",
            "Epoch 77/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.2985 - ssim_loss: 0.2985 - acc: 0.8022 - val_loss: 0.3882 - val_ssim_loss: 0.3882 - val_acc: 0.7928\n",
            "Epoch 78/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.2952 - ssim_loss: 0.2952 - acc: 0.8022 - val_loss: 0.3909 - val_ssim_loss: 0.3909 - val_acc: 0.7953\n",
            "Epoch 79/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.2952 - ssim_loss: 0.2952 - acc: 0.8023 - val_loss: 0.3903 - val_ssim_loss: 0.3903 - val_acc: 0.7935\n",
            "Epoch 80/150\n",
            "8000/8000 [==============================] - 2s 217us/step - loss: 0.2912 - ssim_loss: 0.2912 - acc: 0.8024 - val_loss: 0.3864 - val_ssim_loss: 0.3864 - val_acc: 0.7940\n",
            "Epoch 81/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.2909 - ssim_loss: 0.2909 - acc: 0.8024 - val_loss: 0.3924 - val_ssim_loss: 0.3924 - val_acc: 0.7925\n",
            "Epoch 82/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.2909 - ssim_loss: 0.2909 - acc: 0.8025 - val_loss: 0.3909 - val_ssim_loss: 0.3909 - val_acc: 0.7923\n",
            "Epoch 83/150\n",
            "8000/8000 [==============================] - 2s 217us/step - loss: 0.2897 - ssim_loss: 0.2897 - acc: 0.8024 - val_loss: 0.3879 - val_ssim_loss: 0.3879 - val_acc: 0.7946\n",
            "Epoch 84/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.2881 - ssim_loss: 0.2881 - acc: 0.8027 - val_loss: 0.3938 - val_ssim_loss: 0.3938 - val_acc: 0.7916\n",
            "Epoch 85/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.2884 - ssim_loss: 0.2884 - acc: 0.8026 - val_loss: 0.3861 - val_ssim_loss: 0.3861 - val_acc: 0.7941\n",
            "Epoch 86/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.2852 - ssim_loss: 0.2852 - acc: 0.8028 - val_loss: 0.3884 - val_ssim_loss: 0.3884 - val_acc: 0.7965\n",
            "Epoch 87/150\n",
            "8000/8000 [==============================] - 2s 217us/step - loss: 0.2848 - ssim_loss: 0.2848 - acc: 0.8028 - val_loss: 0.3884 - val_ssim_loss: 0.3884 - val_acc: 0.7960\n",
            "Epoch 88/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.2822 - ssim_loss: 0.2822 - acc: 0.8029 - val_loss: 0.3854 - val_ssim_loss: 0.3854 - val_acc: 0.7969\n",
            "Epoch 89/150\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.2823 - ssim_loss: 0.2823 - acc: 0.8029 - val_loss: 0.3832 - val_ssim_loss: 0.3832 - val_acc: 0.7963\n",
            "Epoch 90/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.2822 - ssim_loss: 0.2822 - acc: 0.8030 - val_loss: 0.3871 - val_ssim_loss: 0.3871 - val_acc: 0.7971\n",
            "Epoch 91/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.2798 - ssim_loss: 0.2798 - acc: 0.8032 - val_loss: 0.3896 - val_ssim_loss: 0.3896 - val_acc: 0.7968\n",
            "Epoch 92/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.2816 - ssim_loss: 0.2816 - acc: 0.8030 - val_loss: 0.3871 - val_ssim_loss: 0.3871 - val_acc: 0.7923\n",
            "Epoch 93/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.2762 - ssim_loss: 0.2762 - acc: 0.8033 - val_loss: 0.3825 - val_ssim_loss: 0.3825 - val_acc: 0.7966\n",
            "Epoch 94/150\n",
            "8000/8000 [==============================] - 2s 217us/step - loss: 0.2730 - ssim_loss: 0.2730 - acc: 0.8035 - val_loss: 0.3881 - val_ssim_loss: 0.3881 - val_acc: 0.7950\n",
            "Epoch 95/150\n",
            "8000/8000 [==============================] - 2s 217us/step - loss: 0.2770 - ssim_loss: 0.2770 - acc: 0.8033 - val_loss: 0.3875 - val_ssim_loss: 0.3875 - val_acc: 0.7942\n",
            "Epoch 96/150\n",
            "8000/8000 [==============================] - 2s 219us/step - loss: 0.2731 - ssim_loss: 0.2731 - acc: 0.8034 - val_loss: 0.3803 - val_ssim_loss: 0.3803 - val_acc: 0.7948\n",
            "Epoch 97/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.2728 - ssim_loss: 0.2728 - acc: 0.8035 - val_loss: 0.3864 - val_ssim_loss: 0.3864 - val_acc: 0.7964\n",
            "Epoch 98/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.2724 - ssim_loss: 0.2724 - acc: 0.8035 - val_loss: 0.3874 - val_ssim_loss: 0.3874 - val_acc: 0.7948\n",
            "Epoch 99/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.2709 - ssim_loss: 0.2709 - acc: 0.8036 - val_loss: 0.3860 - val_ssim_loss: 0.3860 - val_acc: 0.7931\n",
            "Epoch 100/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.2697 - ssim_loss: 0.2697 - acc: 0.8036 - val_loss: 0.3957 - val_ssim_loss: 0.3957 - val_acc: 0.7907\n",
            "Epoch 101/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.2711 - ssim_loss: 0.2711 - acc: 0.8035 - val_loss: 0.3831 - val_ssim_loss: 0.3831 - val_acc: 0.7949\n",
            "Epoch 102/150\n",
            "8000/8000 [==============================] - 2s 212us/step - loss: 0.2655 - ssim_loss: 0.2655 - acc: 0.8039 - val_loss: 0.3861 - val_ssim_loss: 0.3861 - val_acc: 0.7963\n",
            "Epoch 103/150\n",
            "8000/8000 [==============================] - 2s 217us/step - loss: 0.2679 - ssim_loss: 0.2679 - acc: 0.8038 - val_loss: 0.3882 - val_ssim_loss: 0.3882 - val_acc: 0.7966\n",
            "Epoch 104/150\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.2654 - ssim_loss: 0.2654 - acc: 0.8039 - val_loss: 0.3815 - val_ssim_loss: 0.3815 - val_acc: 0.7949\n",
            "Epoch 105/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.2671 - ssim_loss: 0.2671 - acc: 0.8038 - val_loss: 0.3854 - val_ssim_loss: 0.3854 - val_acc: 0.7982\n",
            "Epoch 106/150\n",
            "8000/8000 [==============================] - 2s 217us/step - loss: 0.2694 - ssim_loss: 0.2694 - acc: 0.8037 - val_loss: 0.3825 - val_ssim_loss: 0.3825 - val_acc: 0.7941\n",
            "Epoch 107/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.2645 - ssim_loss: 0.2645 - acc: 0.8039 - val_loss: 0.3842 - val_ssim_loss: 0.3842 - val_acc: 0.7956\n",
            "Epoch 108/150\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.2611 - ssim_loss: 0.2611 - acc: 0.8041 - val_loss: 0.3831 - val_ssim_loss: 0.3831 - val_acc: 0.7948\n",
            "Epoch 109/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.2602 - ssim_loss: 0.2602 - acc: 0.8041 - val_loss: 0.3812 - val_ssim_loss: 0.3812 - val_acc: 0.7963\n",
            "Epoch 110/150\n",
            "8000/8000 [==============================] - 2s 211us/step - loss: 0.2577 - ssim_loss: 0.2577 - acc: 0.8043 - val_loss: 0.3814 - val_ssim_loss: 0.3814 - val_acc: 0.7955\n",
            "Epoch 111/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.2606 - ssim_loss: 0.2606 - acc: 0.8041 - val_loss: 0.3804 - val_ssim_loss: 0.3804 - val_acc: 0.7949\n",
            "Epoch 112/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.2589 - ssim_loss: 0.2589 - acc: 0.8042 - val_loss: 0.3836 - val_ssim_loss: 0.3836 - val_acc: 0.7942\n",
            "Epoch 113/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.2562 - ssim_loss: 0.2562 - acc: 0.8044 - val_loss: 0.3869 - val_ssim_loss: 0.3869 - val_acc: 0.7924\n",
            "Epoch 114/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.2549 - ssim_loss: 0.2549 - acc: 0.8044 - val_loss: 0.3831 - val_ssim_loss: 0.3831 - val_acc: 0.7949\n",
            "Epoch 115/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.2570 - ssim_loss: 0.2570 - acc: 0.8043 - val_loss: 0.3877 - val_ssim_loss: 0.3877 - val_acc: 0.7907\n",
            "Epoch 116/150\n",
            "8000/8000 [==============================] - 2s 213us/step - loss: 0.2537 - ssim_loss: 0.2537 - acc: 0.8044 - val_loss: 0.3819 - val_ssim_loss: 0.3819 - val_acc: 0.7944\n",
            "Epoch 117/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.2514 - ssim_loss: 0.2514 - acc: 0.8046 - val_loss: 0.3823 - val_ssim_loss: 0.3823 - val_acc: 0.7967\n",
            "Epoch 118/150\n",
            "8000/8000 [==============================] - 2s 217us/step - loss: 0.2522 - ssim_loss: 0.2522 - acc: 0.8046 - val_loss: 0.3809 - val_ssim_loss: 0.3809 - val_acc: 0.7928\n",
            "Epoch 119/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.2602 - ssim_loss: 0.2602 - acc: 0.8043 - val_loss: 0.3792 - val_ssim_loss: 0.3792 - val_acc: 0.7962\n",
            "Epoch 120/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.2492 - ssim_loss: 0.2492 - acc: 0.8047 - val_loss: 0.3794 - val_ssim_loss: 0.3794 - val_acc: 0.7939\n",
            "Epoch 121/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.2475 - ssim_loss: 0.2475 - acc: 0.8048 - val_loss: 0.3806 - val_ssim_loss: 0.3806 - val_acc: 0.7945\n",
            "Epoch 122/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.2479 - ssim_loss: 0.2479 - acc: 0.8048 - val_loss: 0.3801 - val_ssim_loss: 0.3801 - val_acc: 0.7939\n",
            "Epoch 123/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.2495 - ssim_loss: 0.2495 - acc: 0.8048 - val_loss: 0.3868 - val_ssim_loss: 0.3868 - val_acc: 0.7979\n",
            "Epoch 124/150\n",
            "8000/8000 [==============================] - 2s 218us/step - loss: 0.2465 - ssim_loss: 0.2465 - acc: 0.8049 - val_loss: 0.3801 - val_ssim_loss: 0.3801 - val_acc: 0.7958\n",
            "Epoch 125/150\n",
            "8000/8000 [==============================] - 2s 217us/step - loss: 0.2454 - ssim_loss: 0.2454 - acc: 0.8049 - val_loss: 0.3832 - val_ssim_loss: 0.3832 - val_acc: 0.7936\n",
            "Epoch 126/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.2458 - ssim_loss: 0.2458 - acc: 0.8049 - val_loss: 0.3802 - val_ssim_loss: 0.3802 - val_acc: 0.7963\n",
            "Epoch 127/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.2483 - ssim_loss: 0.2483 - acc: 0.8047 - val_loss: 0.3804 - val_ssim_loss: 0.3804 - val_acc: 0.7952\n",
            "Epoch 128/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.2436 - ssim_loss: 0.2436 - acc: 0.8050 - val_loss: 0.3822 - val_ssim_loss: 0.3822 - val_acc: 0.7939\n",
            "Epoch 129/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.2428 - ssim_loss: 0.2428 - acc: 0.8050 - val_loss: 0.3849 - val_ssim_loss: 0.3849 - val_acc: 0.7966\n",
            "Epoch 130/150\n",
            "8000/8000 [==============================] - 2s 217us/step - loss: 0.2425 - ssim_loss: 0.2425 - acc: 0.8051 - val_loss: 0.3840 - val_ssim_loss: 0.3840 - val_acc: 0.7926\n",
            "Epoch 131/150\n",
            "8000/8000 [==============================] - 2s 217us/step - loss: 0.2428 - ssim_loss: 0.2428 - acc: 0.8050 - val_loss: 0.3793 - val_ssim_loss: 0.3793 - val_acc: 0.7937\n",
            "Epoch 132/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.2410 - ssim_loss: 0.2410 - acc: 0.8051 - val_loss: 0.3837 - val_ssim_loss: 0.3837 - val_acc: 0.7936\n",
            "Epoch 133/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.2419 - ssim_loss: 0.2419 - acc: 0.8051 - val_loss: 0.3795 - val_ssim_loss: 0.3795 - val_acc: 0.7968\n",
            "Epoch 134/150\n",
            "8000/8000 [==============================] - 2s 217us/step - loss: 0.2381 - ssim_loss: 0.2381 - acc: 0.8053 - val_loss: 0.3812 - val_ssim_loss: 0.3812 - val_acc: 0.7949\n",
            "Epoch 135/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.2366 - ssim_loss: 0.2366 - acc: 0.8054 - val_loss: 0.3825 - val_ssim_loss: 0.3825 - val_acc: 0.7952\n",
            "Epoch 136/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.2384 - ssim_loss: 0.2384 - acc: 0.8052 - val_loss: 0.3803 - val_ssim_loss: 0.3803 - val_acc: 0.7931\n",
            "Epoch 137/150\n",
            "8000/8000 [==============================] - 2s 218us/step - loss: 0.2379 - ssim_loss: 0.2379 - acc: 0.8052 - val_loss: 0.3848 - val_ssim_loss: 0.3848 - val_acc: 0.7918\n",
            "Epoch 138/150\n",
            "8000/8000 [==============================] - 2s 214us/step - loss: 0.2387 - ssim_loss: 0.2387 - acc: 0.8052 - val_loss: 0.3782 - val_ssim_loss: 0.3782 - val_acc: 0.7954\n",
            "Epoch 139/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.2334 - ssim_loss: 0.2334 - acc: 0.8055 - val_loss: 0.3817 - val_ssim_loss: 0.3817 - val_acc: 0.7931\n",
            "Epoch 140/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.2341 - ssim_loss: 0.2341 - acc: 0.8054 - val_loss: 0.3822 - val_ssim_loss: 0.3822 - val_acc: 0.7962\n",
            "Epoch 141/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.2361 - ssim_loss: 0.2361 - acc: 0.8054 - val_loss: 0.3834 - val_ssim_loss: 0.3834 - val_acc: 0.7945\n",
            "Epoch 142/150\n",
            "8000/8000 [==============================] - 2s 218us/step - loss: 0.2375 - ssim_loss: 0.2375 - acc: 0.8054 - val_loss: 0.3808 - val_ssim_loss: 0.3808 - val_acc: 0.7944\n",
            "Epoch 143/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.2336 - ssim_loss: 0.2336 - acc: 0.8054 - val_loss: 0.3796 - val_ssim_loss: 0.3796 - val_acc: 0.7955\n",
            "Epoch 144/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.2317 - ssim_loss: 0.2317 - acc: 0.8056 - val_loss: 0.3805 - val_ssim_loss: 0.3805 - val_acc: 0.7957\n",
            "Epoch 145/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.2313 - ssim_loss: 0.2313 - acc: 0.8056 - val_loss: 0.3835 - val_ssim_loss: 0.3835 - val_acc: 0.7978\n",
            "Epoch 146/150\n",
            "8000/8000 [==============================] - 2s 217us/step - loss: 0.2322 - ssim_loss: 0.2322 - acc: 0.8056 - val_loss: 0.3800 - val_ssim_loss: 0.3800 - val_acc: 0.7967\n",
            "Epoch 147/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.2298 - ssim_loss: 0.2298 - acc: 0.8057 - val_loss: 0.3820 - val_ssim_loss: 0.3820 - val_acc: 0.7964\n",
            "Epoch 148/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.2303 - ssim_loss: 0.2303 - acc: 0.8056 - val_loss: 0.3806 - val_ssim_loss: 0.3806 - val_acc: 0.7957\n",
            "Epoch 149/150\n",
            "8000/8000 [==============================] - 2s 215us/step - loss: 0.2286 - ssim_loss: 0.2286 - acc: 0.8057 - val_loss: 0.3793 - val_ssim_loss: 0.3793 - val_acc: 0.7955\n",
            "Epoch 150/150\n",
            "8000/8000 [==============================] - 2s 216us/step - loss: 0.2291 - ssim_loss: 0.2291 - acc: 0.8057 - val_loss: 0.3876 - val_ssim_loss: 0.3876 - val_acc: 0.7939\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4ec56bacf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ1kxPbAcnxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoded_imgs = autoencoder.predict(test_imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qWQi3ANczkg",
        "colab_type": "code",
        "outputId": "8126a51e-e57c-40f4-e6fa-8ca012c4495f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "images = decoded_imgs.reshape(-1,28,28)\n",
        "\n",
        "for i in range(10):\n",
        "  plt.subplot(2,5,i+1)\n",
        "  plt.imshow(images[i])\n",
        "plt.show()\n",
        "\n",
        "for i in range(10):\n",
        "  plt.subplot(2,5,i+1)\n",
        "  plt.imshow(test_origins[i].reshape(28,28))\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAADSCAYAAABXT0tTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO2deXgc1ZW339ut1mYtlizJlld5kW1s\nFmOIITBg1oSQCYaQEMgXQiZMyAIzIV8yA0lmEjLJZJuEkPkmGwmEsIQlhgSSwIQlEHZjg3e8yUZe\nZXmTtVhrd9/vj3Or1bJkWUt3q6t13ufRI3V1dfWtn6punXvuOecaay2KoiiKfwmMdAMURVGU4aEd\nuaIois/RjlxRFMXnaEeuKIric7QjVxRF8TnakSuKovicYXXkxphLjDGbjDE1xphbE9UoP6Oa9I3q\n0hvVpDeqydAwQ40jN8YEgc3AxcAuYDlwjbX27cQ1z1+oJn2juvRGNemNajJ0sobx2UVAjbV2G4Ax\n5iFgCXBM0bNNjs1lzDC+Mr3Jp5AO2ogQXmatLVdNhHwKaaW5a6DXimrSN5muSz6FtNFC1EZVk6No\npuGAtbb8WO8PpyOfBOyMe70LOKO/D+QyhjPMhcP4yvSm3u7iIHvZQ+12t2nUa4Ix1NtdrLWvNcZt\n7VeXjNcEuVbW8vqANYHM16Xe7mIjb8VvGvWaeDxrl27v7/3hdOQDwhhzA3ADQC75yf46XzCqNLFW\nfo7DqNJkEKguvVFNejOcyc7dwJS415Pdth5Ya++01p5urT09RM4wvi79ySGPdtriN416TUB0AbLj\nNvXSRTXRayWHPKJE4zeNek0GynA68uVAtTFmujEmG7gaeCIxzfInRZTQRgtAdlppYkzfPymiiBKA\nXL1WulFNelNECVGipK0mgSAEggRyc+VnzBgCY8ZgQtmYUHbK76seTRvqB621YeAm4C/ABuARa+36\nRDXMjwRMgDksAJiNahIjYAIAO9BrJYZq0puACXiuEtVkkAzLR26tfRJ4MkFtyQjKTCVY1llrTx/p\nthwT6UQwWUH5neuGp5GI2y6XRbStXbZbGe5a9768GHTYamNaazIyZJ4mnkU6xLDmLEJYa2cnsEVD\nx51LsLgIgMjsqQA0zJYoma58eb/i1QbZf9M2AGxXZypbCWhmp6Ioiu9JetSKkgYcbR3ZiNsslraJ\nyGUQGFcKQOv8SgAOzwoB0DJFPj/lmW5LI3flOwBEDh5KUqNTREBGJQE3KrFdYfc79VaVr/B0y8uV\n1zMl7qFpTjEAY1/bFds1vHuP/OGTRWxMSOagA7OnA7D1GrkvsudLtGhx3j4AOjvl/mg+NBaAwhqx\ni21X6trqoRa5oiiKz1GLfDTjLCTP9x2pEGuq9jLx/f3o4nsBmJddD8C/nX1Z7KP7vj0TgNynm+QY\n4XAKGpw4vHkAM3cWANuuKZE3nNE48zdyzpGad9x2f1iTySJmpVZXAVDz8XEALDp3AwAfKv8TAFs6\nxgPw25+9N/bZyvuaAYg0y+901TIwRnzfbefNA2D7ldLO958kSUqnFkhOzoFwIQARK3bwg9MlIakw\nJBY67e2paXAcapEriqL4nNFrkXs+vmz3FA3IMy3a3iGvo5G+PpVZuFl5ky3WVluFZMnNmL0XgFOy\n5XdpULSamNedUX4gnJ5W1YBx53ToVLHEP3nZswCcmCdVJ/71yCcBmPJfOwD/jTiGjRexMVb8v4cu\nnQNAxQ21ADxVdTcAk7N6JuRMyZI5k19NeE/3xhy3j2eRpxmBQrGw6z92IgATrhLL+6SAzCFtaqoA\nYMV+mQc41CiWe3GhJP8FnQFuclx+1wicplrkiqIoPidzLXLP2nSWVyBfrE1TWABA0yJ5uu59tzzL\ncvfL/lOXSkZweHv3rHvGWudePLkblbSOl8vh8opNAIwJiCbN7vwfX3NK7KMnrBZLNRLxpzYBZyUe\nOFVGFlcVrQRgomdhni6jD8+XPtos8qCzUjsWzgBg/yUyUr1q3GYAit21kWPk2om4CKiDEdEvf293\nhqM9ciQFLR4kbkQOED5F5nvKPySjsfF5YlK/8fhJAEz6m7R/3F65JsZ1HQQgWix9SeCI9BmR5pZk\nt/qYqEWuKIric7QjVxRF8Tn+c604l0kgL09eTpoAQNcECZ1rmSJDu/YSeUa1VsrQOermIQJuLnP8\nIpnI+68ZzwCwqV2SYB5uuUje/3V97Cuj7f50HxwPLwmGCgkl279YkmCucG6GEKL1qy6kbPYvujMd\nIvtleJmuoWTHw5TI9TL1pDoAyoNyK0Tc+XS0ywVjI9E+Pp25eGGGUZfg0zDbvW4V19JfD8ik54eK\n1vT4XIeV929Z/1EAKn+7IfZepLU1iS0ePi1TJanprLGSuPTXXVIhYNof9gMQ3SIhqOGj3Ihmn9PG\nuW+9ZLKRQC1yRVEUn+MPizyuNKQ3CbP3o/MBeNcnVwFwZekfAWiOiqW+vbMMgBWN0wB4fZU8ZUPN\n8vSMWDmmFy5VOkYmKu4rvhiAoa5l6gdiVtfJkgzzzuUSTvWzcySkbJqb4Gt1ucZfXnUFAFXr34kd\nI+rzCeBooZxzXpYkNO2PiDV1yA3dsjfKdeQVDBstBMskHb3+NCkUdWSSbDddYvMVhSTWLtfdkx3u\nGnm2TcIUJ3xV9o80NKSkvUMm/v/qbvUuK33D4YMyiTmxQSY/Y8XivD7hqFK1XrAAXujyCKAWuaIo\nis/xhUXuhYoBNLxf0mdv+GepN//eMRIqt7ZTgvZ/vnMxADtenQzA5BfE7zt35wEAuirF0thaLRZE\nZI48XfeHZXvxVldQagT9XUnDhVx1LpawqopviIX9vYlPATA75JJAnMXx7BHRcMod8rloy8iFVyUM\nd27RArG8Q0asrGYrt8L6jokA5BwcgbalAa2nON/4YrG8Cwrl9yllUijqq5OkanVxQPTbFRYr9NZ7\nPgHAlPWvpaytiaYkJL78CZUymoiWSbKYOehGF16ROTc/xzQZroSLxccefHOjfG4E5tTUIlcURfE5\n6W2RexEq5WWxTdNukoSEjxeJNbk9LM+ir78tBZ0K7pFohFkrxL8VdWVWo87PFUKsTBMo6vFVzzWK\npV+8UiyPiM99wH1hTpNzPPl7qwH4xviXACgwMuKJOmfhyk6xPO745kcAGLtsBZAh8wYuCaqjRM65\nrUOsqY2dEpmzvk2uj4DfSxAMEuNGvTsvktHXx05+FYCKkMwhnJ1XA8CskHQZ7S5K5eq1Uspg2n+v\nBSDql2skrp3ZLXK9Fwcl5f66aa8DcMeHlwAw5Rm5RsIF4guve7f8rjpHUvkbWuXzJd+ZC0Bg2Tr5\nihQmkalFriiK4nPS3CJ3seBuoQOAT1U8CECLmy3/fdNCAOyzMttetFJS66OHJZ3WdroFAlysZ7hc\nol7Om7UFgGy3avdTb54MwNw965JwIiNLsLwcgOwfyGjj6xUvAlAcyO+xX22X+MA/9vqNAFS/IjHW\nR8fP+pnAGDnnlsly6ee46KWgG43MzpX8gj+Nc5EJ7roh01P0T6oG4MoLxRq9svhNACYE5X9fEhCr\n1Fvl/ieHFsj274iefp4/yX9HRh1ehNsnxr8MwMeveE62ny9LvC0cK6P8K4ukrO0MV7Z2f0TmCa7/\nj6sBaP75aQAUPSl9STQFJQrUIlcURfE56W2RO0LN3RmFP66VIu6/ComlveWlKgCmvSUzzrbFPf08\nK9IrDOUsq32niQXxuXESf76xUzJDpz3hMkDb2pJxCiOCFy++8TYpfPTK9B8CUOQs8S635Ns7YYlM\nuPSVmwCYfL+Li/UWX3YaekvE+RkTlHMJHLWS28yQZPHl54jl/a1q2cGLmIp0jFyMcDLxioLtvkDm\njP692FmbrmfIMxKhEXTXwKoO0ed3P5f7cMIan/nG++IdsbTfek5G5ZP+/jAA1XmS3X1hmYtGcQtJ\n7I/K/ZMdllFIu4s//9p0iaTb+S3JlL7jH0Sjkn91i5mv25i0U1CLXFEUxeekt0XuIke8WWCA/H8U\nf7mNylNwxiGp+WA7xWqPHiMTz7hFYhsXiKU1NiAW/A92y5JU+ctrge5aG5lA9PQTALj1Asl6zXVW\nVUNURh0/bxBf3qO/uACA2Q85y8ONasJeLH0GRfBE3SijeJv83rZfopy8fIJ8F1dePt6VsS2SORWa\nmlLZzNThRqrt4+S8x7piRAFke5uV+2WbGxR/+JEvADDrHhnRRtO8jspA8M5hxkOSPPBHzgQg+2Sx\nzNvbZYRqt0s2sHG3Q9aRnhmeHXPlvrp54V8B+P7cpQB84tOfBmDOLd1zUonWTS1yRVEUn5PeFrkj\nPh4zvH3n0A4SFYtjxlQXJ+4q+21/cjoAEw8uG0YL04usSZKdOPnHEnP/wQKJ0AkZsbLub5QKds9/\n4WwAxr8oceKRrqMcxxmIF8WUvUMyfYM7JW683WV25hoxPUtyM2eupD8CY2VEMv/MbQC4YJ7YtbIj\nLHpd9cZnAaj+vmRSp3tFw0HhRuGmUXzeoSbJW2neK6OxcctFi/HPSxRXtN5VRWzruchywI3677/y\nUgB2fUGyXK88+w0AVi46NbZv8G8re3z3cFGLXFEUxef4wiJPCJUSS/3+CWJ9Pt0k9Uam3rsVgHAG\n+IGzKiUCZ+bjYjF8c4LEi+cbsRTqI2Jl3v6yLIw79w3nEx8FlngMZwHZBvGB5xyW2iJeHHnQjdS2\n7pXrpfrQplS3MDW4uju7PyoVMB+a9gMACty14tUXv/fwGQBM/ZHYfJFDaV7VcDhkiSYdpXIthA7L\n6/Jlcs7hWucNOEZf4cWLlzwoMfhPF5wFwJc+/zAAr906PbZv0WpX6ylBVSLVIlcURfE5GW+RezUk\ndn1bnq4XjJGVS665R2bfp+59dWQalkCCJVKlrf0+iRv/2vgXAMg18vqAs8QfaZI42cn/K89vO4L1\nk0car27MkUkS5TTD1dn2MhbGPu8yGTMoryCe4EzJYvzAdVJvZ0qWXBNhxNpc1yUjk/te+jsA5m6U\n+ZZMiuqK4Wo6RcplvsCFhTNurTvXmlr5PcBRu3Uj3JLNcn+dkyc1Wc464d7YPp+pljkH3lCLXFEU\nRWEUWOQd54sV+qeFPwLgrQ7xI0//H/EP+84z7lWELCiIbaq9UeLFfznjfwDwIulXdshz+qlm8XMu\nrZH6GFN2uSzYDKqhMliM07GiWqJXCozECq/slFui4m+S1ZdpFqg3Qt36Can2eGvRY0D3Ckl7IjKK\nu/eARDQVv+3Wo8zQkQmAyZZzPjRfolQieXIHFblcg2hnV98fPBZu/uHgSaL11Cy5V9d0dke5ZO2T\nOZpEVfBRi1xRFMXnHNciN8ZMAe4FxiOr291prf2xMaYUeBioAmqBq6y1aTOl7Vkei76zHOh+Ki5+\nUlb5nn3wjSEfu922sp7ldNIOGCYxnammmi7byVpeBzjRGPMMidTEPeW9le/bzpkbe2vB+8Tv3+Vi\noX/orKnfvSSWOK7Cn80WSyMaEt9dz7y04TEimgwD46ogfm7GCwDkuxVvflF/LgDR2l0J+Z7+dAGq\njTFbSPb9E7fGZGCqrGpTdpqMOLa4EeoDzRJR8Uad+M4bGySLcfIesRkTWVu7P01aaSYlmsThjc4i\n3kJkzrztKpRRWo7LfrXH85G742RNkuzzhR+ROjReTaMvbv1wbNfg7r3Dbnc8A7HIw8AXrbXzgDOB\nG40x84BbgeestdXAc+71qMBgqOZk3m3ey7s4n11spcU2UctGSqkAWIdqMuo1gf51AZr1/umpSZAQ\no1GT4XJci9xaWwfUub+bjTEbgEnAEuA8t9tvgBeAW5LSyiHQeskpANxadgcADe5hOu+78iQcjn2R\nY/LIQarCZZkQ+baQDtrYzx5OYzE1rINEaeI95cdLXHPbfLGo6v+h2992balY5H9ulHN+9NVFABRu\ndfUyKsXPG3bPbeOyXBO5QnxKNUkAXVXiIz4vv9ZtkRHby2/KfEN1eOgjtnj60wXwVgZNqi7xa94e\nOkPWtp1RKPHxdV0Sz1zTJNdXU5Nbj7LF1Ws/IKM3G03cXEF/moTI9nZL2bXiRTDlNLpcgha5Tw7N\nk/tn0la55+wuyew8enQSyJfR3eH3yQpc7/5XuXa+Nv4VAJ5rE43Nv5d2f2fXEDPUj8GgfOTGmCrg\nVGAZMN518gB7EdfLqKPNHqGZwxRTSicd5Liyn6gmqslRHK0L3dGOo1aXozUJdHdJo1aToTDgqBVj\nTAHwKHCztbbJxPndrLXWGNPnI9sYcwNwA0Au+X3tklC8+sp8TrIbQ67i3611iwEI79idsO8K2zBr\neI05LCDLhCBOgURpYrLET9dwbhUAde8Ra+D/znsxtk/QiGW9bL/sk31QLImWKucTL5TP5G8Vaydr\nX5Nrf+IjMlKhybBw1239IvEBlwbkemmISCRPxevGa2xCv3ZEdPEinMrGxTYdcOU+riqW2OaJIeeC\nFkOdlwMzAdhyUDJes/dIBcBkZD6nzbXiRhuhI+5+yZU+o/kUiQevKZd5hJwGV3nVPWuirqsp/juZ\nb/ifuf8NwIwsud9Wdsgo78s/uh6A8W90j/ISfecNyCI3xoSQTvwBa+1jbnO9MabSvV8J7Ovrs9ba\nO621p1trTw+R09cuviRqo6zhNSYwlQojQ69scuiwEqalmqgmHsfSBQjB6NTlWJp4S8mNRk2Gw3E7\nciOm913ABmvt7XFvPQFc5/6+Dng88c1LT6y1vM0KxlDINDM7tr2cidSx3XupmjC6NYH+dQE8U3lU\n6dKfJl3E6v6MKk2Gy0BcK2cD1wJrjTGr3LavAN8FHjHGXA9sB65KThMHR3CCuNUun7QagJ1hecL/\n7WFZRGFidPgp+Y0cZC87KKCY1+0zAMziRKYxJxZqBxwmAZp4pTHrXSThNQtleLYw753YPofd0lNj\nXenV3YXOqqmQiaqs3XKMSX+Toj7RPYkNfYLUajIcPFdV0wk9J6zWdjkNN0op00QNffvTZTubi1yo\nXVLuH295w2hZcWzbxBPFDeCVqgg5t1xuQNz1L1kpolW6Rtwy0f0HSTT9abKLbSRTk76wYTn3/B3i\ncsw6IiUv5i/cAcBlZ0pfUp0t902ukWvHK4Vd6Eofe0vAXbftMgD23i0hnROWyuejSVzAeyBRKy9z\n7JDjCxPbHH8w1pRxER/q873TWMyzduk6a+1FKW7WiKKa9E1/umDZbK09PbUtGnn60yTfFtJkD1Wn\nuEm+J2NS9AO5YnXuv2gqALNyngfgngYpJTn5fw8B3enrfsFbEqpc1sTl+RPkGi8LtfTatyPsFnkt\nkIkpc0gmN2c/0iw7rHJla5NoGaQ7gTEu7K1IhvCtLlnDK2scOCKjmEwoXuCFDAa6us+mIl+uhWJn\ngTdGZYSyqV0m8mpfl0nOWc/vASB8JIMWkDgW3sT25loApv1Z/O4rKyU56srx3oLUooWn5gqXTPW9\nGlkusvP3MmM84WkJqCjdJcmIqbjfNEVfURTF5/jeIjchsTrtfAmb2n+mPC9r3NNy6TqJt5rbLMWR\n/GaRe8kHxQ/IUnSBx8SifLaqe0TePlGK/QTb5dzn7ZbJftsgoWORRrdwcIYVgBoKxhUbi+6TEdwf\nWmSE89ROSQQaVyp+zlh4rZ81cyGD0c3d8yl775D74cLL/hmAwlWiQ8UKmV+ZufZtAMJNLT2OMRqI\ntkuSnXldFns/4W25Vh6olMXJ76lwheoick14oZklB7yl3yTJJzwCC7WoRa4oiuJzfGuRe4k/gSJ5\nSoazXfnRV2Sm/u7aSwCYulKejtFDh1PdxMTiLEPPZ87bm2NvhTb0nItORqKP73EWtm0SH3H1ffL7\nx/suByDbDVqCLZIgE3WJZFj/W6Q2zkIseFyWIZvzlIxko97iIs7y9v/ZJgBPi8NSahb3O7Ch527p\nNNOkFrmiKIrP8Z9Fbnpan9bNqgdXShGg0tXybCr1Sk92Oou8M4MXGFYL/Pg4jSJNzvR+cz0AU1b3\nvAWi3mIbGaqpN+eSyLK0ysijFrmiKIrP8YdFHm+Fm57PnpiFcVSZTS+rLZGlWpXMQy1TJRNQi1xR\nFMXnGJtCX6AxZj9wBDiQsi9NLmX0fS7TrLXlAzlABmoCfeuimgxDE8hIXVST3gypT0lpRw5gjFmR\nKfUlEnUumaQJJOZ8VJPkHicdUE16M9RzUdeKoiiKz9GOXFEUxeeMREd+5wh8Z7JI1LlkkiaQmPNR\nTZJ7nHRANenNkM4l5T5yRVEUJbGoa0VRFMXnaEeuKIric1LWkRtjLjHGbDLG1Bhjbk3V9yYKY8wU\nY8zzxpi3jTHrjTGfd9tvM8bsNsascj+XDvK4vtVFNemNatI3ydBFNYnDWpv0HyAIbAVmANnAamBe\nKr47gedQCSx0fxcCm4F5wG3Al0ajLqqJajJSuqgmPX9SZZEvAmqstdustZ3AQ8CSFH13QrDW1llr\n33J/NwMbgEnDPKyvdVFNeqOa9E0SdFFN4khVRz4J2Bn3ehfDv7hHDGNMFXAqsMxtuskYs8YYc7cx\npmQQh8oYXVST3qgmfZMgXVSTOHSyc5AYYwqAR4GbrbVNwM+AmcACoA744Qg2b0RQTXqjmvSN6tKb\nRGiSqo58NzAl7vVkt81XGGNCiOAPWGsfA7DW1ltrI9baKPBLZMg3UHyvi2rSG9WkbxKsi2oSR6o6\n8uVAtTFmujEmG7gaeCJF350QjCyrfhewwVp7e9z2yrjdrgDWDeKwvtZFNemNatI3SdBFNYkjJQtL\nWGvDxpibgL8gs813W2vXp+K7E8jZwLXAWmPMKrftK8A1xpgFgAVqgU8P9IAZoItq0hvVpG8Sqotq\n0hNN0VcURfE5OtmpKIric7QjVxRF8TnakSuKovgc7cgVRVF8jnbkiqIoPkc7ckVRFJ+jHbmiKIrP\n0Y5cURTF52hHriiK4nO0I1cURfE52pEriqL4HO3IFUVRfI525IqiKD5HO3JFURSfox25oiiKz9GO\nXFEUxedoR64oiuJztCNXFEXxOdqRK4qi+BztyBVFUXyOduSKoig+RztyRVEUn6MduaIois/RjlxR\nFMXnaEeuKIric7QjVxRF8TnakSuKovgc7cgVRVF8jnbkiqIoPkc7ckVRFJ+jHbmiKIrP0Y5cURTF\n52hHriiK4nO0I1cURfE52pEriqL4HO3IFUVRfI525IqiKD5HO3JFURSfox25oiiKz9GOXFEUxedo\nR64oiuJztCNXFEXxOcPqyI0xlxhjNhljaowxtyaqUX5GNekb1aU3qklvVJOhYay1Q/ugMUFgM3Ax\nsAtYDlxjrX07cc3zF6pJ36guvVFNeqOaDJ2sYXx2EVBjrd0GYIx5CFgCHFP0bJNjcxkzjK9Mb/Ip\npIM2IoSXWWvLVRMhn0Jaae4a6LWimvRNpuuSTyFttBC1UdXkKJppOGCtLT/W+8PpyCcBO+Ne7wLO\nOHonY8wNwA0AueRzhrlwGF85Qhgjv48zeqm3uzjIXvZQu91tylxNBkG93cVaXm+M29RLF9VEr5V9\nWfVs6HojftOo18TjWbt0e3/vJ32y01p7p7X2dGvt6SFykv11ycHa43bigztcBmiSYFSTvhlNuthw\nGDj+fTaaNBkow+nIdwNT4l5PdttGLTnk0U5b/KZRrwmILkB23KZRr4tq0psc8ogSjd806jUZKMPp\nyJcD1caY6caYbOBq4InENGsECQTlx5junwFSRAlttABk+0IT71yTTBElALkZd60MA9WkN0V2LFGi\nqCaDZ8gdubU2DNwE/AXYADxirV2fqIb5kYAJMIcFALNRTWIETABgB3qtxFBNehMwAXLJB9Vk0Axn\nshNr7ZPAkwlqy4hgcsTHFhhbLBs6OgCINDYN6XhlphIs66y1pyekgUkkkB0CwGTLrH+k5Yi8EY0k\n4+sa/aBJL9yIJauiDABbUgSAaZPrJLp3X2zXaHv7YI/uT02SSBYhrLWzR7odfkMzOxVFUXzOsCxy\nX+F83YH8fADs3CoA9pwnlniXC0Wd+nSL7P7mxthHbVdnihqZWuwJMwHYeotYnWaLiDDzPrEyI5u3\njkzD0oBgSQkADZfMAWD8Z94B4Lyy5QCsbZ4MQM1/nhz7TO6f35Q/kjOiUXyKCbk5bds9kWsj7hpJ\nUDScWuSKoig+J+Mtcu9paE6YAcDmT44F4KKzVgPwqbEyl7KtU5Km7ua9AMzYXho7RnhvvfyRwFjy\nEcWNTjZ9TkYnr571IwC2L8oD4LrATQDM+M86AKKtralu4cjhfOIN7xNL/JZv3A/ARXkH5G1n+6zL\n3wLAjWUnxT6am7JGKknFi1Qzzs71LOmB3v/uGgqWyGjfTpkgm/cfju0SqZdRr8TODx+1yBVFUXxO\nxlrkgVyxj1ouPQWAMTftAuDXVQ8BMCkovvDCgDx9F+bsAaDhCvET/7np72LHmniXRHNEm5uT3eyU\nEHCROrecLQFHZUGxxPdHuwCIOJeeycrYy+OYBMvHAVD5GZkfOD9vPwB5RjSLuszD5qiIVFzb0f1h\nH/jGvfvC5Mr52E75n0fbXCLbIK3OQJ4bhwTEJoy2tAzuOGmId38Exsso3bZKNFLk4CHZ4ej/81Hz\nb5EF1QBs+pBoEy0Wq3va77prwuS9LH2JTZBeapEriqL4nIwzuTyf+N5PLgTgls8/CMD7xojFnW+8\nrGixQgPI07Q4IE/Zz4x7FYDWa7uzpzc/I9EdvL1ZfvvY2gCwJ4nFcGnBs26LaFHbJfMC+XWiyVBL\nHPuZQxfLXMp/TLwLgFzT8xbpsGLB/mbf+QDkvHMg9l5ivJ1JIC472RQWAtB2WhUA7aViWZe+JCPW\n8G6ZFznW6MIbpZkTJdT78AkSV1+6bK98zLMw/YjTyc6X+33jx0Sroq1i705cKqO0yIGDsp+LPDFB\nNzoplUinmiVyP33gXIlwOhIWC3/1i90RTvmeju6zw/WVq0WuKIric7QjVxRF8TmZ41pxw6Ldn5eM\n50f/6b8AmJklw5ygyeuxe5ftOXSMODdCoQs5urh4Xey9VdNOBSBngxeOlP6TWv1R8xGZdCkLZPfY\nvqZtKgDlq136+ZHRE3boTQIW/oMU2zspu0G20/O6qY/IEHjt/ScCULFjWaqamBBMvpxn7Qfl9UWn\nrAXg5VkSFDD9pzLpGZvY85qdVPMAABRqSURBVD7nXADRd82X978p+nS0yr1g17hysn52x7l7f9uH\nxV10/YV/BeDu8AUA2C5xqx2dzGOj8jtaXABAxckSrnz52LcA2Nwp4Ycrg92uFQ/vs8NFLXJFURSf\nkzEWeWSxWM2P3PQDAGaH+l7+qTEqFsfqTrG0co08ZZuj8npCsPdkTThfnnd+L2HvTQRfeK4kQ4WM\nWFneBN5bh6W8fM52scYiPginSxRt50tiz12zJDnKC8n0JsM7rFjiV6/9JAAT7hVLNuozjdqqKwD4\nt3P+CMBZedsAeGGuTICbPDcCOSoZxgutq7lS3r9/xt0A/KlpAQAr8k5JcsuTT9ZEsZwXn78GgPyg\njEwnvSj/40iDW9Dp6FGH0yg8TrR5/8SVAMwKSeG9w1HRjriK2LHJTduj/vqQUYtcURTF5/jeIs+q\nlKfo3//kOQBmh/pOlK4Li6V92RqxqAKPSOJHW5k8JptnyRPy6xf8AYDSOMs8EHZP4AQ9PUeK4ORK\nAD5e9nug29psjsq5r9xYBcDcutGzaLkXTlf65VoApro5laNHK9/YvwiA8uslzTrio+QwkxWK/V17\nhZzvBwoklC7fnWdRoZsPyXIF1ILegiPyOzKvCoBPX/IMACdni5VaXvIaAL+/+BwAJr85sPVtE4ox\nw/o+b6S68UsyIr12rIQgf2v9pQBMfWkTcOwRqqfVtiUyZv95sRRPG+NGNStbpwFQ8Up3qGokwYlT\napEriqL4HN9a5IEx4gNvv0+epp8ZK76+oOm5dNkOZ4l/8Jv/AkD5A+IfjraLRVI6RvxXjZfKbHzh\nRZKOOyGre4Hzrjx53uX5eUYeeOdjkwCYE/LWFRXrc2dELImi9WK52Y6OXp/NVLrOFd/uHVU/BiBk\nJPIg4kZfL7fLCO+NL78LgOx9K1LdxGETKOieL5o+p67He5u65NoOPysLZ0T3yf3hRWZ4i48cniX3\nyeIxUt4530U8VbmEqYkX7QTA3C7bU3YNGYPJzh7898UlSXVcKNfAx85/CYC9YSl2FXpOfkdbNvV7\nqI4LZZ7giQ/K/MrkLLmfGqNS/vqhP50LwIx3VnZ/KMF9iVrkiqIoPsd/Frkr1rPpuxLH+8ac2wEI\nGbdcmbOkfnp4OgBLb5WytGVPSbps1Jstdk9k4+KHOz4mkRpe8aw9kfzYVxbs8reF6i2ScN1V4t8s\nDsg5hxGr67eH3g3AxBckNjga8VckxlDw/KILfyCxvpXBnvHinjbfrV0CQF6N+Dd9qUxleezPBSU1\nAOwMi6X9qbXXAjDpfrG0I0eO9PhotEPup5I1MjfwVlsVAKdliwXuFRGrzJcR7EGXph6u25vYczgW\n1mK7Bp/enjVhfOzvAzdK288eIyU4VrdP7bGvF7ETK+fsfN9t7xVL/J6fSB80NSu/x+cORqSPqXxV\n2peokrV9oRa5oiiKz/GdRW7PFEv8l5f+CoB8I5ZFQ0Selguf/mcA5nxO4nxzO96Qzx11HG8mf8sX\nZwHwyoIfuOOJJA82nhDbN7tG/IppWxTpONTeKOdyZ7HEDgdkpXLqIzLSeOLV0wCYu1usNV9n5w2Q\ng9fKOf9LufzfvRGdR7uLG69rlCy/yWPdCC47xT7gYeCNOvadPS627frC/wVgY6dEMEWfkfeiTe8c\n4yBi67VPlAJSASPXRpsV/+8hF/H05h6J+JhWKq/N/u4IjWRaosCgygd7muy8ZkZs29fnyOIhM0My\nIt0fkf9581kyl2SD0uccmSTnXjRPimY9tUB84hXBgh7f4WWN/+Kg+MbzN7nRXIKyOPtCLXJFURSf\n4wuL3ItQAdj8OXn2zAmJX6vFiqV05l//SbY7S/x4FpMXU33rEompLnaz8K1ucYX7Ni2K7VvV6M9F\niAOuZOnlV74MQKk7R8//+/tmidSZ/gexmKKN/omNHirGLRqQ9xHx4RYfVW/Gm2Op6XKlSV+RyIXg\nfvEJJ9OqSjTBMilL3HZJU2zbzJAslPFks9T9CLXI+QTHiW/btkvUlimRJREPnSn3yfSbJHLjPLfE\nXZe779rd70DA1RvJdV2KSU8b0dPEntO97Fp1tiy7lu8CWeZnyzzZT88QSz14plwTXp9T6ObpigN9\nZ4/XR8SS/9uvpQ8ZXytegWQuPJKeaiuKoigDJq0tcs+fdXhJ9wK3vz7r5wCMDUjT/9omT9gTvioV\nx8LHscQ9i2zXj8RP/KFC8Q1muUoqO13ExriHumegY8tg+Yy2c+cC8InSOwDIdxaEN5/wsw2SjTd9\ns9Mu3JXqJqacwLTJAFw39RUAsuiZd+BFYex1ftK2cnndNVl8yVlNkpcQaehMfmOHiovIaj1ZzvXi\nqlWxt0qD8j+ekSNWaNMlEqVycIFEeYUmyLVxbpWMQj9cLJmbC3JkRJLvfOSebdkadQskuO3paol7\n0W5t8yWX4ua5f469NSEoZ+PNj4WMjFDLguIzb7VxRVKA0FHXjEdLVEYz73njMwBU/U7mnCLJniNA\nLXJFURTfk5YWuVf/ov1iybj69Ncei713Ro5YFAEk6qTLyr72OEtMedb9lu9KlcRlp/0QgHzjFmm2\nYsn/n5XXAzD56e56I1G/RXE466P+E2IhTMvq6Qfe4mKISx90sfd1EkOcydEq3v9/xwclfviCfLGW\ngqZnxIFXW+WpBrn2Cmtle7BRtMQPMfbOKo5my++yUPe9UeyujYvyZWm3U86QEW7QWdQhNyLxqgrl\nOGO0y10ani3qvb87InMIzXtcVMth8cFH0lQnT5Mu221VH3Yn0+4s8eaovPeXFplD+mOdeASWTJSs\n1+uKpG8IuWMccD7x834j2ePTvyE5K6mwxD3UIlcURfE5aWmRB6eKb6/jnyTb8oqC7bH3PF+2F3mx\nrk32jfnmnMXh1Ygw0yW+lZ+KL3B1tfiL89yKQV6d6TsPS6zo5NucReLjRWSzKqRuxrdOeRyAHOON\nXkSzH+y+BICiFyQCIZWWw0gRmCHZeld/VFZ9mZjVs7q8F63ytotWee1Xsnj3hKUSrRFtlMiPqB+0\nctERY96oBeDuFxbH3lp0qfi+57oVkKa4aocRZ4k3u8++2i6+5KiV++pIVPSanyMrKBUHZAT7YrPM\nwxRvcF3JgUM92pA2uP9v/jI5/1/ecVnsrZ+4HIGiWmeau5Fp0RaJ4rKVMnKt/ZbcV+2Fsl+zs8Q/\ncsuXAKh6UOYTRmJcqxa5oiiKz0kvi9xZ042nih/zA5NeACDXdDcz6CzvDpdR5q3iceRsWeFkzFax\nNDZ+VqJZHvvAfwMwP9ubkRafuGedvtguvr0/fflC+a61UkvYz/7ivUska21xnje3IBZFnbMgNj88\nB4Dxh15LedtSTXCcXAcbvyJRKPeUyP8356hMTi9T8aOvScRB9X3iD420+nfd0ki9RKbM/mJ3zPT3\nfy+1VfbcKOd728mS7Ts2IOe5olWund9sOAOAsmIZmVaOkRFJ+zgZ3YWM3D+PvCVr5M59ydVpb0rT\nkay7n721SMt++fqx93V9jCmWa6Z+iWRGf6n8BQCCLirorKduBmD2g/0cK0WoRa4oiuJzjmuRG2Om\nAPcC4xH3z53W2h8bY0qBh4EqoBa4ylrbkIhGRbN6xm1G4qzjCD1X6flgoVhOU34oT9rCoFid5+eK\nBZEf6NsXuqZTLIp/+46sGORVR7QD8O2121bWs5xO2gHDJKYz1VTTZTtZy+sAJxpjniGBmgwELzIj\n+3KxxLwqh945P9wkkRgTn6pz2xM36kgLTeJqTAedNbX9BvHh/vac/wfAuEDPKoeeNn86IhmMs28T\nv2iiLPH+dAGqjTFbSPD9czS2qzvmPfi8VHuselP0+dH7rwGg4QTRLuuI/B5bJ9dG3WmST9FaJddW\nVkD0Wlcvek160q0otE2iYAbiG+9Pk1aaSYUm/Y+45RybLpgNwF+u/z4AlUHR4rk26VPm3rw+bu+R\nZSAWeRj4orV2HnAmcKMxZh5wK/CctbYaeM69HhUYDNWczLvNe3kX57OLrbTYJmrZSCkVAOtQTUa9\nJtC/LkCz3j89NQkSYjRqMlyOa5Fba+uAOvd3szFmAzAJWAKc53b7DfACcMuwWuOe5mNXSizqb2vE\n//bx09+M7VLqHj2en6rMrZf3vjFSHyHfiOUQcKfmWVxelMvPDosv/Q9fuhiAcX9x1REHMcueY/LI\ncavrZJkQ+baQDtrYzx5OYzE1rINEaTIIArMlO+/r1bLuqLfupJdx9tMXZR5gzs7VCf/udNDEqxsN\ncOj94tf83LXiAz4x28talevDuy42d4k2t3/nagBKtiTW39mfLsBBt1vKr5VIk4xYix6WkWhJuauQ\nWCRx9eEKsdibpoumhwtk+7J9MqdUulzur+I3JYol3NKzjnl/9KdJiFjOQ8o18Qi47O+bvv0I0F2r\n/mBURvvfufEGALJb02e1qEH5yI0xVcCpwDJgvOvkAfYirpe+PnODMWaFMWZFF+lf+nOwtNkjNHOY\nYkrppIMcExu6qyaqSQ+O1gXwni6jVpejNQl0d0mjVpOhMOCoFWNMAfAocLO1tsnE+SOttdbEii30\nxFp7J3AnQJEpHZBTNrpd/G3lv5CMqu9PPT/23ufLnwegNOAytPAy0qQ9jVYsrPqIvP9Sq9Qb/96r\n7wNg3r/LsXP2rvAaOJAm9UnYhlnDa8xhAVkm1COANNGa9Iv7X2y6XirYLcxxsbwuWmWbC32esVRG\nHbYzeXVCRkQTF+2ElzMA5H1CbIwlBRsACJme+Qe7wtIBvP/PXwRg7mPi70zkvEE8aXOtHI0biUb2\ny+Ag4CzrLHd/FdfIPEuoWSzlvP3ShJK3xaK3h93atnbwnuJ01WTvJyWH4MoCqccTdV7wM/78BQBm\nP7080V85bAZkkRtjQkgn/oC11otpqzfGVLr3K4F9yWliehK1UdbwGhOYSoWR5IlscuiwMvxSTVQT\nj2PpAlJnYjTqcixNvE5zNGoyHI7bkRsxve8CNlhrb4976wngOvf3dcDjiW9eemKt5W1WMIZCppnZ\nse3lTKSOWBaqasLo1gT61wXwlu4ZVbr0p0kXsdHiqNJkuAzEtXI2cC2w1hjj1cP8CvBd4BFjzPXA\nduCqRDXKWxQi5wVZJGLDzfNj7138KXG3XH2yuEYOh2UyZl+7TMas2iHD6/GPy1B67ApZQGDObjnW\n8crcDoRGDrKXHRRQzOtWFjSexYlMY04s1A44TAI16Q9vcmbOqTuAbjeTl/T0VLNolrvBTUwlwX0w\nkpoYN+HdeOLY2Labpz0FdJc79lwmra4o1nf3yqLcs3/lytI2J2dRjf502c7mIhdql9D7Z0g4F4u3\nwHBgpwQPjHMJPqUFcp+ZsAsKaBMXZsT9Hgz9abKLbYyYJs5FF31Pz4jHv7XJuZ/wVVeWNg2TBQcS\ntfIyYI7x9oWJbY4/GGvKuIgP9fneaSzmWbt0nbX2ohQ3a0RRTfqmP12wbLbWnp7aFo08/WmSbwtp\nsoeqU9wk35NeKfpH4VnmgZe7C+PPWSGTL6smzwTAdIiFZV1Ro1mtbqk3V9zIByWOho11FsKOQzLZ\nubpTRidegfx7lkqo5bRDb/bxaf9j3YIYhdu6Q+DWtEqRrDNzZRSyNyKjlvsPngfAlm/MAyB37Up3\nkPSzskaUqPiqbXtHz9fuvvK22y53h2WAfl6hvQ9UrQO6Sxp/9vV/BKC6ce3INGwAaIq+oiiKz0lr\ni7wvom5xWGreGdmGpBGeVTT2YUnW+OxqKfxUvE2sqOlPiIURScD8QFriWYMruhcDWX7DAgAevUSW\nsytbK77dorfE95uzU1LVB5MIltG4ENZAnsT8B1yxMVyZW5wFHvUsce9ayiD9jDv3kJHRfXPUG23I\nr8BYWUQjcuBgr8+ONGqRK4qi+BzfWeRKHzirqOgpSWopekJ8e1FnNaXjLHtSiLcOl8soZNpK8Xt6\nfvRkROxkAl7kk3F+Yrrc3JOL5om6RCHrh4U1hkjUnevS+88DYOsHZSGJvPUuM7lcRimm0S040ZU+\nC3CrRa4oiuJz1CLPIKJJioX2Jc7yTierKS1xvnHP0o42Ot+3l3o/ivA0mPILGc3VvSaLbEzdLwmm\nniVO4FjR2COHWuSKoig+Ry1yRRmNOEvcy4q1UTd3oHMIsaJy2dsPyAbPAg/J/IE3nxDxYujTIHJH\nLXJFURSfY2wKn8DGmP3AEeBAyr40uZTR97lMs9aWD+QAGagJ9K2LajIMTSAjdVFNejOkPiWlHTmA\nMWZFptSXSNS5ZJImkJjzUU2Se5x0QDXpzVDPRV0riqIoPkc7ckVRFJ8zEh35nSPwnckiUeeSSZpA\nYs5HNUnucdIB1aQ3QzqXlPvIFUVRlMSirhVFURSfk7KO3BhziTFmkzGmxhhza6q+N1EYY6YYY543\nxrxtjFlvjPm8236bMWa3MWaV+7l0kMf1rS6qSW9Uk75Jhi6qSRzW2qT/AEFgKzADyAZWA/NS8d0J\nPIdKYKH7uxDYDMwDbgO+NBp1UU1Uk5HSRTXp+ZMqi3wRUGOt3Wat7QQeApak6LsTgrW2zlr7lvu7\nGdgATBrmYX2ti2rSG9Wkb5Kgi2oSR6o68knAzrjXuxj+xT1iGGOqgFOBZW7TTcaYNcaYu40xJYM4\nVMboopr0RjXpmwTpoprEoZOdg8QYUwA8CtxsrW0CfgbMBBYAdcAPR7B5I4Jq0hvVpG9Ul94kQpNU\ndeS7gSlxrye7bb7CGBNCBH/AWvsYgLW23lobsdZGgV8iQ76B4ntdVJPeqCZ9k2BdVJM4UtWRLweq\njTHTjTHZwNXAEyn67oRgjDHAXcAGa+3tcdsr43a7Alg3iMP6WhfVpDeqSd8kQRfVJI6U1CO31oaN\nMTcBf0Fmm++21q5PxXcnkLOBa4G1xphVbttXgGuMMQuQtbZrgU8P9IAZoItq0hvVpG8Sqotq0hPN\n7FQURfE5OtmpKIric7QjVxRF8TnakSuKovgc7cgVRVF8jnbkiqIoPkc7ckVRFJ+jHbmiKIrP0Y5c\nURTF5/x/feRxlpY4FX0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAADSCAYAAABXT0tTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkCuKorgcNeSKoigu5/8DicsB8BwX8bUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}
